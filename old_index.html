---
layout: page
---
    <center>
    <img src="{{ '/assets/images/index/profile_photo.png' | relative_url }}" width="320" height="320"/>
    </center>
	<p></p>
	<p>
        I'm Abrar! I'm a senior in Computer Science at the <a target="_blank" href="https://www.cs.utexas.edu/">University of Texas at Austin </a> (Class of 2021)
    </p>

	<p>
        At UT, I primarily conduct research with the <a target="_blank" href="https://www.cs.utexas.edu/~larg/bwi_web/">Building-Wide Intelligence Project</a>. 
        Here, I gained experience in robotics, localization, navigation, perception, and manipulation working on various projects over the years.
    </p>

    <p>
        These last two summers, I have been interning at <a target="_blank" href="https://www.sandia.gov/index.html">Sandia National Laboratories</a>,
         where I have been working with the <a target="_blank" href="https://neuroscience.sandia.gov/research/NERL_Lab.html">Neural Exploration and Research Lab</a>. 
         I have worked on brain-inspired navigation and localization, and am currently working on evolving spiking circuit motifs. 
    </p>

    <h2>Research</h2>

		<!-- <ol> -->
        <!-- <li>A. Anwar, et al. <a target="_blank" href="https://icons.ornl.gov/schedule/schedule_videos/">"Evolving Spiking Circuit Motifs using Weight Agnostic Neural Networks."</a> Poster presented at the <a target="_blank" href="https://icons.ornl.gov/">International Conference on Neuromorphic Systems</a>; July 2020</li> -->
        <!-- <li>A. Anwar, et al. <a target="_blank" href="assets/images/index/icons_poster_2020.png">"Evolving Spiking Circuit Motifs using Weight Agnostic Neural Networks."</a> Poster presented at the <a target="_blank" href="https://icons.ornl.gov/">International Conference on Neuromorphic Systems</a>; July 2020</li> -->
		<!-- <li>F. Wang, J. B. Aimone, A. Anwar, and S. Musuvathy. <a target="_blank" href="https://www.osti.gov/biblio/1569159-brainslam">"BrainSLAM: Robust autonomous navigation in sensor-deprived contexts".</a> SAND Report, SAND2019-11302 R, 2019.</li> -->
        <!-- <li>A. Anwar, B. Holman., C. Sheehan, J. Huang. "Using Human-Inspired Signals to Disambiguate Navigational Intentions." Poster presented at the UT Undergraduate Research Forum; April 2020.</li> -->
        <!-- <li>A. Anwar, B. Holman, M. Shaposhnikov. <a target="_blank" href="assets/images/index/bbslam_urf.png">"Bounding Box SLAM: A Fast, Selective SLAM."</a> Poster presented at the UT Undergraduate Research Forum; April 2019.</li> -->
		<!-- </ol> -->
    <!-- </p> -->
    
    <style type="text/css">
        #img table,tr, td {
            border: 1px solid transparent;
            align:"center";
            border-spacing: 25px;
            border-collapse: collapse;
            border-width: 1px;
            padding: 5px;
            padding-left: 50px;
        }
        td{
            background: white;
        }
        
    </style>


    <table>
        <tbody>
        <tr><th class="year" colspan="2">2020</th></tr> 
           <tr>
               <td style="width: 50%;">
                    <img src="assets/images/index/spiking_wann_logo.png" style="width:90%;">
               </td>
               <td>
               <b>Evolving Spiking Circuit Motifs using Weight Agnostic Neural Networks.</b>
               <br><u>Abrar Anwar</u>, Craig Vineyard, William Severa, Srideep Musuvathy, Suma Cardwell<br>
               <a target="_blank" href="https://icons.ornl.gov/">International Conference on Neuromorphic Systems</a>. Poster. 2020<br>
               Sandia Computer Science Research Institute Summer Proceedings. 2020 (in review)<br>

                <a target="_blank" href="">[Technical Report]</a> 
                <a target="_blank" href="assets/images/index/icons_poster_2020.png">[Conference Poster]</a> 
                <br><br>
                An evolutionary, weight agnostic method is used to generate spiking neural networks used for classification, control, and various other tasks
               </td>
           </tr>

           <tr>
            <td style="width: 50%;">
                 <img src="assets/images/index/bwi.jpg" style="width:90%;">
            </td>
            <td>
            <b>Using Human-Inspired Signals to Disambiguate Navigational Intentions.</b>
            <br><u>Abrar Anwar</u>, Blake Holman, Connor Sheehan, Jeffery Huang<br>
            UT Undergraduate Research Forum. Poster. April 2020<br>

             <a target="_blank" href="assets/images/index/hallway_urf_2020.jpg">[Poster]</a> 
             <br><br>
             Specific navigational cues are used to study how users interact with various signals on our BWIBots in a hallway scenario.
            </td>
        </tr>

           <tr><th class="year" colspan="2">2019</th></tr> 
           <tr>
            <td style="width: 50%;">
                 <img src="assets/images/index/brainslam_logo.png" style="width:90%;">
            </td>
            <td>
            <b>BrainSLAM: Robust autonomous navigation in sensor-deprived contexts.</b>
            <br>Felix Wang, James B. Aimone, <u>Abrar Anwar</u>, Srideep Musuvathy.<br>

             <a target="_blank" href="https://www.osti.gov/biblio/1569159-brainslam">[Technical Report]</a> 
             <br><br>
             Brain-inspired approaches to navigation and localization are explored in a noisy, data-sparse environment for a hypersonic glide vehicle.
             Rotation invariant feature representation methods are explored to increase accuracy and reduce map storage.
            </td>

            <tr>
                <td style="width: 50%;">
                     <img src="assets/images/index/bbslam_logo.png" style="width:90%;">
                </td>
                <td>
                <b>Bounding Box SLAM: A Fast, Selective SLAM.</b>
                <br><u>Abrar Anwar</u>, Blake Holman, Misha Shaposhnikov<br>
                UT Undergraduate Research Forum. Poster. April 2019<br>
    
                 <a target="_blank" href="assets/images/index/bbslam_urf.png">[Poster]</a>
                 <a target="_blank" href="https://github.com/MishaShapo/Visual-Localization">[Code]</a> 

                 <br><br>
                 Semantic information is combined with ORB-SLAM in order to reduce drift and localization error in dynamic environments.
                </td>
            </tr>
        </tbody></table>


        <h2>Some Projects</h2>


        <table id="main_tab">
            <tbody>
                <tr><th class="year" colspan="2">2020</th></tr> 

               <tr>
                   <td style="width: 50%;">
                        <img src="assets/images/index/deepHHD_logo.png" style="width:90%;">
                   </td>
                   <td>
                   <b>DeepHHD: Learning Helmholtz-Hodge Decomposition to Predict Optical Flow</b><br>
    
                    <a target="_blank" href="assets/papers/DeepHHDReport.pdf">[Report]</a> 
                    <a target="_blank" href="https://github.com/AbrarAnwar/DeepHHD">[Code]</a> 
                    <br> In "Geometric Foundations of Machine Learning" course
                    <br><br>
                    By treating an optical flow estimate as a vector field, we can use a deep neural network to estimate the Helmholtz-Hodge Decomposition, whose sum is the optical flow itself. 
                   </td>
               </tr>

               <tr>
                <td style="width: 50%;">
                     <img src="assets/images/index/gp_report_logo.png" style="width:90%;">
                </td>
                <td>
                <b>Detecting Muscle Cocontraction Through Sliding Window Gaussian Processes</b><br>
 
                 <a target="_blank" href="assets/papers/GPCocontraction.pdf">[Report]</a> 
                 <a target="_blank" href="https://github.com/AbrarAnwar/CocontractionGPs">[Code]</a> 
                 <br> In graduate-level "Machine Learning" course
                 <br><br>
                 Implemented a Gaussian process (GP) from scratch in order to detect muscle cocontraction in the hyperparameters in a set of sliding window GPs
                </td>
            </tr>
            </tbody></table>
	


